---
title: "HW5"
author: "Matt Untalan"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


### Due date

Due: November 16 at 11:59pm. 

### Points

| Problem         | Points    |
|:--------------- |:--------- |
| Problem 0       | 20        |
| Problem 1       | --        |
| Problem 2       | 40        |
| Problem 3       | 40        |
| Optional survey | No points |


### Problem 0

This "problem" focuses on structure of your submission, especially the use git and GitHub for reproducibility, R Projects to organize your work, R Markdown to write reproducible reports, relative paths to load data from local files, and reasonable naming structures for your files. This was not prepared as a GitHub repo.

```{r load_libraries}
library(tidyverse)
```

## Problem 2

The raw dataset includes 12 variables: the individual's unique id number; homicide report date (listed as yyyymmdd); victim information such as first and last name, age, and sex; location of the homicide including coordinates; and status of the case.

Create city_state variable and classify current disposition variable into solved/unsolved
```{r status}
homicide = 
  read_csv("prob2_data/homicide-data.csv", na = c("", "Unknown")) %>%
  mutate(
    city_state = paste(city, state, sep=","),
    status = case_when(
        disposition == "Closed by arrest" ~ "Solved",
        disposition == "Closed without arrest" ~ "Unsolved",
        disposition == "Open/No arrest" ~ "Unsolved"))
```

Unsolved Cases for Baltimore
```{r baltimore}
balt = 
  homicide %>%
  filter(city_state == "Baltimore,MD")

balt_sum =
  balt %>%
  summarize(
    unsolved = sum(status == "Unsolved"),
    n = n()
  )

balt_prop = 
  prop.test(
    x =
      balt_sum %>%
      pull(unsolved),
    n =
      balt_sum %>%
      pull(n)
  )

broom::tidy(balt_prop) %>%
  select(estimate, conf.low, conf.high) %>%
  knitr::kable()
```

The estimated proportion of homicides that are unsolved in Baltimore, MD is 64.556%.  We are 95% confident that the true proportion falls in between 62.756% and 66.316%.

Unsolved Cases for All Cities
```{r cities}
prop_test_all = function(cities) {
  city_tot =
    cities %>%
    summarize(
      unsolved = sum(status == "Unsolved"),
      n = n()
    )
  city_prop = 
     prop.test(
    x =
      city_tot %>%
      pull(unsolved),
    n =
      city_tot %>%
      pull(n)
  )
  return(city_prop)
}

city_crime = 
  homicide %>%
  relocate(city_state) %>%
  nest(data = uid:status) %>%
  mutate(
      results = map(data, prop_test_all),
      results_tidy = map(results, broom::tidy)
  ) %>%
  select(city_state, results_tidy) %>%
  unnest(results_tidy) %>%
  select(city_state, estimate, conf.low, conf.high) %>%
  janitor::clean_names()
```

Unsolved Homicides by City Plot
```{r unsolved_plot}
city_crime %>%
  mutate(
    city_state = fct_reorder(city_state, estimate)
  ) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf_low, ymax = conf_high)) +
  labs(title = "Estimated Proportion of Unsolved Cases per City",
       x = "City",
       y = "Estimated Proportion of Unsolved Cases") +
  coord_flip()
```

## Problem 3

Generate Datasets with Design Elements; Estimate Mu and P-value
```{r ttest}
mu0_datasets = map(1:5000, ~ rnorm(n = 30, mean = 0, sd = 5))

estimate = function(n_obs = 30, mu, sigma = 5) {
  x = rnorm(n = n_obs, mean = mu, sd = sigma)
  tibble(mu_hat = mean(x),
         p = t.test(x, mu = 0)$p.value
         )
}

mu0_ttest = 
  expand_grid(n = 30, mu = 0, sigma = 5, dataset = 1:5000) %>%
  mutate(est_dataset = map(.x = mu, ~ estimate(mu = .x))) %>%
  unnest(est_dataset)

mu_repeat_ttest = 
  expand_grid(n = 30, mu = c(1,2,3,4,5,6), sigma = 5, dataset = 1:5000) %>%
  mutate(est_dataset = map(.x = mu, ~ estimate(mu = .x))) %>%
  unnest(est_dataset)
```

Plot for Assessing Power in Part 1
```{r power}
power = 
  mu_repeat_ttest %>%
  group_by(mu) %>%
  summarise(
    rejectH0 = sum(p < 0.05),
    count = n()
  ) %>%
  mutate(prop_rejectH0 = rejectH0/count) %>%
  ggplot(aes(x = mu, y = prop_rejectH0)) + 
  geom_point(alpha = 0.5) + 
  geom_line(alpha = 0.5) +
  labs(title = "Proportion of Null Hypothesis Rejection by True Mean",
       x = "True Mean (mu)",
       y = "Proportion of Null Hypothesis Rejections")
```

As the true mean and effect size increase, the power also increases.  By a true mean of 4, power nears 1.